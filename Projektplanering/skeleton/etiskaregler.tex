% See: https://student.portal.chalmers.se/sv/chalmersstudier/kandidat-och-examensarbete/Sidor/etik-kandidat-examensarbete.aspx

\section{Societal and Ethical Aspects}

It is difficult to see how the project could come to cause direct harm to anyone.
With that said,
if the product ever becomes say an ``officially'' recommended tool
for students of a particular course or readers of some educational book,
or if students were queried during implementation as a way to gather feedback,
then that would place extra importance on the quality of the software.
Students can be in a very high-stress environment,
always pestered by the next deadline,
and we all know the unnecessary frustration
a piece of buggy computer software can cause.
The point being that if it is required that the software be used,
it leaves students with little or no recourse in avoiding additional frustration
should the software experience be subpar.
This can be alleviated by keeping the tool optional for any potential user -
only presented as an helpful aid -
and therefore not forcing it upon anyone who could see it as destructive.

Another area of moral problems is whether the time
would be better spent on something else.
There is a risk that the produced product
will never actually be applied in practice,
or that the report becomes, if you will, a ``non-seller''.
However,
through having evaluated the shortcomings of pre-existing tools in this space
we hope to bring improvements compared to what is available,
as mentioned in previous sections.
Also we choose to focus on the places where
the product is most likely to see potential use.
Thus the risk is minimised.

Lifting the discussion to the wider context,
our contribution could help to enrich society's general understanding of logic,
if only by a miniscule amount,
and it is hard to see anything regrettable in that.
The 1942 short story ``Runaround'' by Isaac Asimov \autocite{asimov50}
exemplifies how the ability to perform deductive logic when hard-pressed
can mean a difference between life and death,
there in regard to the proposed \emph{Three Laws of Robotics}.
Combined with the coming uprising of artificial intelligence (AI)
and knowledge on the ethics of AI, or current lack thereof,
it would almost be doing a disservice to not proceed with the project.

As the negative points given above are comparatively minor,
and as we have outlined ways of mitigating them,
we deem it not necessary to
consider societal and ethical aspects any further in the main report.
